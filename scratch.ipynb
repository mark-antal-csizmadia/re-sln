{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad6c6d0-953d-47c6-b347-53cbcff6ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d08d4d1-5852-4add-a4fb-d5466b986be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7739e4-a729-46ee-92d2-ab77543bb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_params(dataset_name, datapath):\n",
    "    if dataset_name == \"cifar10\":\n",
    "        # stds are different in paper wtf\n",
    "        train_dataset = datasets.CIFAR10(os.path.join(datapath, dataset_name), train=True, transform=transforms.ToTensor(), download=True)\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        pass\n",
    "    elif dataset_name == \"clothing1m\":\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    means = train_dataset.data.mean(axis=(0,1,2)) / 255.0\n",
    "    stds = train_dataset.data.std(axis=(0,1,2)) / 255.0\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6deaae-da09-4cee-9ad8-6f16200f31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(dataset_name, **kwargs):\n",
    "    means, stds = kwargs[\"means\"], kwargs[\"stds\"]\n",
    "    \n",
    "    if dataset_name == \"cifar10\":\n",
    "        train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4), \n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(means, stds)])\n",
    "\n",
    "        test_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                             transforms.Normalize(means, stds)])\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        pass\n",
    "    \n",
    "    elif dataset_name == \"clothing1m\":\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    return train_transform, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f031fd74-9aa9-492e-97a0-2a65bfcd771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(dataset_name, datapath, **kwargs):\n",
    "    train_transform, test_transform = kwargs[\"train_transform\"], kwargs[\"test_transform\"]\n",
    "    \n",
    "    if dataset_name == \"cifar10\":\n",
    "        train_dataset = datasets.CIFAR10(os.path.join(datapath, dataset_name), train=True, transform=train_transform, download=True)\n",
    "        test_dataset = datasets.CIFAR10(os.path.join(datapath, dataset_name), train=False, transform=test_transform)\n",
    "    \n",
    "    elif dataset_name == \"cifar100\":\n",
    "        pass\n",
    "    \n",
    "    elif dataset_name == \"clothing1m\":\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2919107-f8e0-42bd-b5cc-8ea3a2055e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(dataset_name, datapath):\n",
    "    means, stds = get_normalization_params(dataset_name, datapath)\n",
    "    \n",
    "    transform_params = {\"means\": means, \"stds\": stds}\n",
    "    train_transform, test_transform = get_transforms(dataset_name, **transform_params)\n",
    "    \n",
    "    transforms = {\"train_transform\": train_transform, \"test_transform\": test_transform}\n",
    "    train_dataset, test_dataset = get_splits(dataset_name, datapath, **transforms)\n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6577a3-6e81-4222-a4e1-3c19556ead81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "def get_datta_loaders():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d927463-aac7-4905-9d93-71083f3e79e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"cifar10\"\n",
    "train_dataset, test_dataset = get_datasets(dataset_name, datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd6309d-2388-4db9-95d1-a5ce3f9cad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data/cifar10\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.49139968 0.48215841 0.44653091], std=[0.24703223 0.24348513 0.26158784])\n",
      "           )\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data/cifar10\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.49139968 0.48215841 0.44653091], std=[0.24703223 0.24348513 0.26158784])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8930c5-59fd-498a-b04c-584bf1d8eb23",
   "metadata": {},
   "source": [
    "### Symmetric Noise CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78caa7c9-448c-4608-a258-ad972a86f4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.tensor(train_dataset.targets)\n",
    "noisy_targets = targets.detach().clone()\n",
    "\n",
    "indices = torch.arange(targets.size()[0])\n",
    "\n",
    "p_mask = torch.ones_like(targets[indices]) * 0.4\n",
    "flip_mask = torch.bernoulli(input=p_mask)\n",
    "flip_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee70886-b852-4ff8-94fa-6202626b1e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.,  ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_mask = (flip_mask * (-1)) + 1\n",
    "keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1b98a1-eadb-4185-b8b6-732e8c58e55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19936,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(flip_mask.numpy() == 1.0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47efe9b-1034-4206-a203-5dba34683233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor(10)\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor(list(train_dataset.class_to_idx.values()))\n",
    "print(labels)\n",
    "labels_len = torch.tensor(labels.size(dim=0))\n",
    "print(labels_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e1ed39-1ee4-4281-b4e8-0f74a58c72a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "tensor([8, 8, 9,  ..., 9, 6, 9])\n",
      "torch.Size([50000])\n",
      "tensor([    0,     1,     2,  ..., 49997, 49998, 49999])\n"
     ]
    }
   ],
   "source": [
    "targets = torch.tensor(train_dataset.targets)\n",
    "\n",
    "p_mask_label = torch.ones_like(labels) / labels_len\n",
    "print(p_mask_label)\n",
    "flip_mask_label = torch.distributions.categorical.Categorical(p_mask_label)\n",
    "flipped_targets = flip_mask_label.sample(sample_shape=targets[indices].shape)\n",
    "print(flipped_targets)\n",
    "print(flipped_targets.shape)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e7b854-db17-4199-b1ce-93175975853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8., 0., 9.,  ..., 0., 0., 9.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_flipped_targets = flipped_targets * flip_mask\n",
    "masked_flipped_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86d623df-543c-4916-978f-46d4efa5b5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 9,  ..., 9, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36ecfcfb-0f51-4d0f-8b8d-67d2093638c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 9., 0.,  ..., 9., 1., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_targets = targets[indices] * keep_mask\n",
    "masked_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38041a11-eaf2-4225-8a68-cc3d633c11ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000])\n",
      "tensor([8, 9, 9,  ..., 9, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "noisy_targets_sub = (masked_targets + masked_flipped_targets).long()\n",
    "print(noisy_targets_sub.shape)\n",
    "print(noisy_targets_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b0bf0b-1790-4933-9dbd-9b88fe20be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 9, 9,  ..., 9, 1, 1])\n",
      "tensor([8, 9, 9,  ..., 9, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "noisy_targets[indices] = noisy_targets_sub\n",
    "print(targets)\n",
    "print(noisy_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1646512a-26ac-490a-81ed-8658e87a10d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64322"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(noisy_targets.numpy() == train_dataset.targets)[0].size / np.array(train_dataset.targets).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96161261-1c34-4823-bdb6-ed98ca6de82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to cifar10, add paper noisy labels, save mine, set seed for my noisy label generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51051fdf-5e47-4ca8-83a9-e951df16559d",
   "metadata": {},
   "source": [
    "### Asymmetric Noise CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0822fe2a-b37f-4be3-976c-224e3bd406d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 9,  ..., 9, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89ab075f-083e-4e74-a8fe-7fda64b2b666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43df5453-1465-4595-bd42-2635e00578b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(range(10))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071da460-c8dc-4269-8ef3-932d73b00e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1,  2,  3, -1,  5,  6,  7,  8,  9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[[1,4]] = -1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30ef63c5-29af-405c-90b8-448ba225c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,     2,    14,  ..., 49963, 49971, 49997])\n",
      "tensor([9, 9, 9,  ..., 9, 9, 9])\n",
      "torch.Size([5000])\n",
      "tensor([0., 1., 0.,  ..., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "targets = torch.tensor(train_dataset.targets)\n",
    "noisy_targets = targets.detach().clone()\n",
    "\n",
    "indices = torch.where(targets == train_dataset.class_to_idx[\"truck\"])[0]\n",
    "print(indices)\n",
    "print(targets[indices])\n",
    "\n",
    "p_mask = torch.ones_like(targets[indices]) * 0.4\n",
    "flip_mask = torch.bernoulli(input=p_mask)\n",
    "print(flip_mask.shape)\n",
    "print(flip_mask)\n",
    "keep_mask = (flip_mask * (-1)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c22f72c6-44f7-417e-a4eb-be5776d75904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1,  ..., 1, 1, 1])\n",
      "torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "p_mask_label = torch.zeros_like(labels)\n",
    "p_mask_label[train_dataset.class_to_idx[\"automobile\"]] = 1.0\n",
    "print(p_mask_label)\n",
    "flip_mask_label = torch.distributions.categorical.Categorical(p_mask_label)\n",
    "flipped_targets = flip_mask_label.sample(sample_shape=targets[indices].shape)\n",
    "print(flipped_targets)\n",
    "print(flipped_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ef266b0-e6e3-4342-8ec6-2669f6b9a214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9,  ..., 9, 9, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac5a2efd-af59-43eb-9dbe-bf6f3b9f94ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000])\n",
      "tensor([0., 1., 0.,  ..., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "masked_flipped_targets = flipped_targets * flip_mask\n",
    "print(masked_flipped_targets.shape)\n",
    "print(masked_flipped_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df6e5804-a98d-4cf9-a443-0ea6403365c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 0., 9.,  ..., 9., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_targets = targets[indices] * keep_mask\n",
    "masked_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "474a12aa-db9c-4b7f-b24c-832e6e07af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000])\n",
      "tensor([9, 1, 9,  ..., 9, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "noisy_targets_sub = (masked_targets + masked_flipped_targets).long()\n",
    "print(noisy_targets_sub.shape)\n",
    "print(noisy_targets_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66e2570b-d948-4964-97e9-93489adf680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 9,  ..., 9, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "708c3e9f-9684-401a-be52-4e50b2362e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 9, 9,  ..., 9, 1, 1])\n",
      "tensor([6, 9, 1,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "noisy_targets[indices] = noisy_targets_sub\n",
    "print(targets)\n",
    "print(noisy_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7785aeef-ba41-49cd-92f5-b0358174e89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.392"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.where(targets == train_dataset.class_to_idx[\"truck\"])[0]\n",
    "torch.where(targets[indices] != noisy_targets[indices])[0].size()[0] / indices.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66275940-8853-4c78-bfb3-7e610be754a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000])\n",
      "torch.Size([1960])\n",
      "tensor([    1,     2,    14,  ..., 49963, 49971, 49997])\n",
      "tensor([    2,    15,    67,  ..., 49945, 49971, 49997])\n"
     ]
    }
   ],
   "source": [
    "dirty_indicator_indices = torch.where(targets != noisy_targets)[0]\n",
    "print(indices.size())\n",
    "print(dirty_indicator_indices.size())\n",
    "print(indices)\n",
    "print(dirty_indicator_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf2587-a40c-4485-be28-7f9e2ff0e438",
   "metadata": {},
   "source": [
    "Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02d56e46-25bd-488a-8e0d-5a69ae428d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae2ee616-f6a8-43af-829d-8155df20716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(os.path.join(datapath, dataset_name), train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "targets = torch.tensor(train_dataset.targets)\n",
    "\n",
    "src = \"truck\"\n",
    "dsts = [\"automobile\"]\n",
    "dataset_name = \"cifar10\"\n",
    "p = 0.4\n",
    "\n",
    "indices, dirty_indicator_indices, noisy_targets = apply_noise(train_dataset, src, dsts, p)\n",
    "noisy_targets.size()\n",
    "#targets[indices] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d755dac-b2a7-4bf0-a386-4a21db585ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4008"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_indicator_indices.size()[0] / indices.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b0dafd9-08a0-49d1-9bf0-1e6fcef295cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c92dd1f-9899-4d8a-9578-b853a5ed2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test.npy\", train_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e78e67d6-9d99-47f3-8e3f-21eb6c31e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = np.load(\"test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "b62a56e2-3f07-41fe-9657-901880c93363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(train_dataset.data == train_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a00b5e12-afa2-4d8d-b996-9779cf0e39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inherent_label_noise(train_dataset, src, dsts, p):\n",
    "    # clean targets\n",
    "    targets = torch.tensor(train_dataset.targets)\n",
    "    # copy clean targets to noisy targets\n",
    "    noisy_targets = targets.detach().clone()\n",
    "\n",
    "    # get all labels\n",
    "    labels = torch.tensor(list(train_dataset.class_to_idx.values()))\n",
    "    labels_len = torch.tensor(labels.size(dim=0))\n",
    "\n",
    "    # get src targets indices (indices in all dataset)\n",
    "    # asym: get indices of src targets\n",
    "    indices = torch.where(targets == train_dataset.class_to_idx[src])[0]\n",
    "    #print(indices)\n",
    "\n",
    "    # p_mask eg 0.4 for each src target, each target flips with probability p\n",
    "    p_mask = torch.ones_like(targets[indices]) * p\n",
    "    # flip_mask is 0s and 1s  (flip is 1s)\n",
    "    flip_mask = torch.bernoulli(input=p_mask)\n",
    "\n",
    "    # keep_mask is inverse of flip_mask (keep is 1s)\n",
    "    keep_mask = (flip_mask * (-1)) + 1\n",
    "\n",
    "    # p_mask_label is dst label probability distribution to flip to (length is number of classes), sums to 1.0\n",
    "    # asym: dst class is 1.0, all else 0.0\n",
    "    p_mask_label = torch.zeros_like(labels, dtype=torch.float)\n",
    "\n",
    "    p_mask_label[[train_dataset.class_to_idx[dst] for dst in dsts]] = 1.0 / len(dsts)\n",
    "    print(p_mask_label)\n",
    "\n",
    "    # flip_mask_label is categorical distribution with params p_mask_label for each dst class\n",
    "    flip_mask_label = torch.distributions.categorical.Categorical(p_mask_label)\n",
    "\n",
    "    # flipped_targets is dst labels for each src label that the src label can flip to\n",
    "    # for now, only one dst, so all in flip_targets is dst class label\n",
    "    flipped_targets = flip_mask_label.sample(sample_shape=targets[indices].shape)\n",
    "\n",
    "    # mask the flipped_targets to get the actually flipped instances (ones not to be flipped are 0s, ones to be flipped are dst labels)\n",
    "    masked_flipped_targets = flipped_targets * flip_mask\n",
    "\n",
    "    # mask the actual targets to keep the ones not flipped (ones not to be flipped are original labels, ones to be flipped are 0s)\n",
    "    masked_targets = targets[indices] * keep_mask\n",
    "\n",
    "    # add vectors together - kept ones remain, flipped ones are flipped\n",
    "    noisy_targets_sub = (masked_targets + masked_flipped_targets).long()\n",
    "\n",
    "    # insert into noisy_targets the flipped targets\n",
    "    noisy_targets[indices] = noisy_targets_sub\n",
    "\n",
    "    # get the indices of the noisy instances (indices in all dataset)\n",
    "    dirty_indicator_indices = torch.where(targets != noisy_targets)[0]\n",
    "    \n",
    "    return indices, dirty_indicator_indices, noisy_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0cabe209-1ab2-42d6-ba1d-d48384926db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
      "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx.keys())\n",
    "print(train_dataset.class_to_idx.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43b1f7f6-0c11-46ca-bdc5-65a514384681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "tensor([    1,     2,    14,  ..., 49963, 49971, 49997])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([    1,     2,    14,  ..., 49963, 49971, 49997]),\n",
       " tensor([    1,     2,    50,  ..., 49911, 49917, 49926]),\n",
       " tensor([6, 1, 1,  ..., 9, 1, 1]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "12122049-7f3e-49f8-ba79-58dcd7a36aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_symmetric_noise_rules(dataset_name, train_dataset):\n",
    "    if dataset_name == \"cifar10\":\n",
    "        labels = list(train_dataset.class_to_idx.keys())\n",
    "        noise_rules = []\n",
    "\n",
    "        for src in labels:\n",
    "            dsts = labels.copy()\n",
    "            dsts.remove(src)\n",
    "            p = 0.4\n",
    "\n",
    "            noise_rule = {\"src\":src, \"dsts\":dsts, \"p\":p}\n",
    "            noise_rules.append(noise_rule)\n",
    "\n",
    "    elif \"cifar100\":\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception\n",
    "        \n",
    "    return noise_rules\n",
    "\n",
    "def make_asymmetric_noise_rules(dataset_name, train_dataset):\n",
    "    if dataset_name == \"cifar10\":\n",
    "        noise_rules = [\n",
    "            {\"src\":\"truck\", \"dsts\":[\"automobile\"], \"p\":0.4},\n",
    "            {\"src\":\"bird\", \"dsts\":[\"airplane\"], \"p\":0.4},\n",
    "            {\"src\":\"cat\", \"dsts\":[\"dog\"], \"p\":0.4},\n",
    "            {\"src\":\"dog\", \"dsts\":[\"cat\"], \"p\":0.4}\n",
    "        ]\n",
    "\n",
    "    elif \"cifar100\":\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception\n",
    "        \n",
    "    return noise_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e78c2-59c4-4985-890e-23ff91ac4d08",
   "metadata": {},
   "source": [
    "symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "58b5267b-b7a2-4841-97bc-1ee739df5ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[{'src': 'airplane', 'dsts': ['automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], 'p': 0.4}, {'src': 'automobile', 'dsts': ['airplane', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], 'p': 0.4}, {'src': 'bird', 'dsts': ['airplane', 'automobile', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], 'p': 0.4}, {'src': 'cat', 'dsts': ['airplane', 'automobile', 'bird', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], 'p': 0.4}, {'src': 'deer', 'dsts': ['airplane', 'automobile', 'bird', 'cat', 'dog', 'frog', 'horse', 'ship', 'truck'], 'p': 0.4}, {'src': 'dog', 'dsts': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'frog', 'horse', 'ship', 'truck'], 'p': 0.4}, {'src': 'frog', 'dsts': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'horse', 'ship', 'truck'], 'p': 0.4}, {'src': 'horse', 'dsts': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'ship', 'truck'], 'p': 0.4}, {'src': 'ship', 'dsts': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'truck'], 'p': 0.4}, {'src': 'truck', 'dsts': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship'], 'p': 0.4}]\n",
      "tensor([   29,    30,    35,  ..., 49941, 49992, 49994])\n",
      "tensor([0.0000, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "        0.1111])\n",
      "tensor([    4,     5,    32,  ..., 49993, 49998, 49999])\n",
      "tensor([0.1111, 0.0000, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "        0.1111])\n",
      "tensor([    6,    13,    18,  ..., 49987, 49991, 49995])\n",
      "tensor([0.1111, 0.1111, 0.0000, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "        0.1111])\n",
      "tensor([    9,    17,    21,  ..., 49979, 49982, 49983])\n",
      "tensor([0.1111, 0.1111, 0.1111, 0.0000, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "        0.1111])\n",
      "tensor([    3,    10,    20,  ..., 49981, 49984, 49990])\n",
      "tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.0000, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "        0.1111])\n",
      "tensor([   27,    40,    51,  ..., 49964, 49980, 49988])\n",
      "tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.0000, 0.1111, 0.1111, 0.1111,\n",
      "        0.1111])\n",
      "tensor([    0,    19,    22,  ..., 49962, 49966, 49996])\n",
      "tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.0000, 0.1111, 0.1111,\n",
      "        0.1111])\n",
      "tensor([    7,    11,    12,  ..., 49965, 49978, 49986])\n",
      "tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.0000, 0.1111,\n",
      "        0.1111])\n",
      "tensor([    8,    62,    69,  ..., 49968, 49976, 49985])\n",
      "tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.0000,\n",
      "        0.1111])\n",
      "tensor([    1,     2,    14,  ..., 49963, 49971, 49997])\n",
      "tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "        0.0000])\n",
      "tensor([    0,     2,     5,  ..., 49989, 49992, 49994])\n",
      "0.3997\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(os.path.join(datapath, dataset_name), train=True, transform=transforms.ToTensor(), download=True)\n",
    "noise_rules = make_symmetric_noise_rules(dataset_name, train_dataset)\n",
    "print(noise_rules)\n",
    "\n",
    "targets = torch.tensor(train_dataset.targets)\n",
    "noisy_targets = targets.detach().clone()\n",
    "\n",
    "for noise_rule in noise_rules:\n",
    "    indices_per_rule, dirty_indicator_indices_per_rule, noisy_targets_per_rule = \\\n",
    "        make_inherent_label_noise(train_dataset, noise_rule[\"src\"], noise_rule[\"dsts\"], noise_rule[\"p\"])\n",
    "    noisy_targets[indices_per_rule] = noisy_targets_per_rule[indices_per_rule]\n",
    "\n",
    "print(torch.where(targets != noisy_targets)[0])\n",
    "print(torch.where(targets != noisy_targets)[0].size(dim=0) / targets.size(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab1e91-1590-4b49-83a3-77e44bd96750",
   "metadata": {},
   "source": [
    "asymmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0c99a152-695a-4360-929a-fc7da0786df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[{'src': 'truck', 'dsts': ['automobile'], 'p': 0.4}, {'src': 'bird', 'dsts': ['airplane'], 'p': 0.4}, {'src': 'cat', 'dsts': ['dog'], 'p': 0.4}, {'src': 'dog', 'dsts': ['cat'], 'p': 0.4}]\n",
      "tensor([    1,     2,    14,  ..., 49963, 49971, 49997])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([    6,    13,    18,  ..., 49987, 49991, 49995])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([    9,    17,    21,  ..., 49979, 49982, 49983])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([   27,    40,    51,  ..., 49964, 49980, 49988])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([    2,     6,     9,  ..., 49987, 49991, 49995])\n",
      "7918\n",
      "0.15836\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(os.path.join(datapath, dataset_name), train=True, transform=transforms.ToTensor(), download=True)\n",
    "noise_rules = make_asymmetric_noise_rules(dataset_name, train_dataset)\n",
    "print(noise_rules)\n",
    "\n",
    "targets = torch.tensor(train_dataset.targets)\n",
    "noisy_targets = targets.detach().clone()\n",
    "\n",
    "for noise_rule in noise_rules:\n",
    "    indices_per_rule, dirty_indicator_indices_per_rule, noisy_targets_per_rule = \\\n",
    "        make_inherent_label_noise(train_dataset, noise_rule[\"src\"], noise_rule[\"dsts\"], noise_rule[\"p\"])\n",
    "    noisy_targets[indices_per_rule] = noisy_targets_per_rule[indices_per_rule]\n",
    "\n",
    "print(torch.where(targets != noisy_targets)[0])\n",
    "print(torch.where(targets != noisy_targets)[0].size(dim=0))\n",
    "print(torch.where(targets != noisy_targets)[0].size(dim=0) / targets.size(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bab2f-d672-45ea-b334-63a0a25de63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
